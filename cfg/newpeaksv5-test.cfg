[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=4
subdivisions=1
width=1552
height=1480
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 0
exposure = 0
hue=0

learning_rate=0.001
burn_in=1000
max_batches = 6240
policy=steps
steps=6000,12000
scales=.1,.1

# 0
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# 1
[maxpool]
size=2
stride=2

# 2
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 3
[maxpool]
size=2
stride=2

# 4
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 5
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 6
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky


[route]
layers=-5

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=16
activation=leaky

[reorg]
stride=2

[route]
layers=-1,-4

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=96
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear


[region]
anchors =  0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828
bias_match=1
classes=1
coords=4
num=5
softmax=1
jitter=.3
rescore=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
